{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `lab08`—“The Secret Weapon that Won the War”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/lab09-header-bkgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❖ Objectives\n",
    "\n",
    "-   Apply a brute-force attack to solve an encryption problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way back in the `encode` lab, you built a tool to reproduce the encryption algorithm of the World War II-era Nazi Enigma machine.  Today, you will recapitulate some of the work required to solve such an encryption if the encoding offsets are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enigma:  A Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enigma uses a polyalphabetic cipher, in which each letter pressed on a mechanical keyboard would both be encoded and trigger a rotor to change position.  Since the rotor determines the alphabet (either the offset or a randomized substitution pattern), each letter press *changes the subsequent encoding alphabet*.  It's like changing the offset according to some rule every time you encoded a letter above.\n",
    "\n",
    "To clarify this, first think of a pair of rotors, or wheels.  The inner (red) wheel represents the base alphabet (of the message), and the outer (blue) wheel represents the letter each inner letter maps to (the encoding).  An offset of one produces the following diagram:\n",
    "\n",
    "![](./img/rotor-base.png)\n",
    "\n",
    "A rotor cipher simply chains multiple wheels together, so that a change in one wheel produces an encoded letter *but also changes the position of the encoding rotor* for the next letter.  For instance, before encoding the letter `'A'` from the inner wheel, the rotor configuration is at left.  After encoding `'A'` (to `'B'`), the wheel advances and gives us the *new* configuration at right, in which `'A'` now maps to `'C'`.\n",
    "\n",
    "![](./img/rotor-pair.png)\n",
    "\n",
    "In order to think about a rotor cipher, you will have to accept a message, and for each letter in that message you will need to:\n",
    "\n",
    "1.  Encode the letter.\n",
    "2.  Advance the offset of the rotors by one.\n",
    "\n",
    "-   We provide a function `rotor_cipher` which accepts a string `message` and a list `m` of the starting offsets for the $n$ rotors.  `rotor_cipher` should `return` the message transformed by successively apply the rotor cipher across the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "def mapper( letter,offset=1 ):\n",
    "    '''\n",
    "    Map a single-character string letter forward by its offset.\n",
    "    '''\n",
    "    return alphabet[ ( alphabet.index( letter ) + offset ) % 26 ]\n",
    "\n",
    "def decode_n_rotors( message,m ):\n",
    "    decoded = ''\n",
    "    message = message.upper()\n",
    "    \n",
    "    for letter in message:\n",
    "        if letter in alphabet:\n",
    "            decoded += mapper( letter,sum( m ) )\n",
    "            # Rotate all rotors back.\n",
    "            m[ 0 ] = ( m[ 0 ] - 1 ) % 26\n",
    "            for i in range( 1,len( m ) ):\n",
    "                if m[ i - 1 ] % 26 == 0:\n",
    "                    m[ i ] = ( m[ i ] - 1 ) % 26  # here as well\n",
    "        else:\n",
    "            decoded += letter\n",
    "    \n",
    "    # Finally, return the result.\n",
    "    return encoded\n",
    "\n",
    "def encode_n_rotors( message,m ):\n",
    "    encoded = ''\n",
    "    \n",
    "    # Convert the message to upper-case.\n",
    "    message = message.upper()\n",
    "    \n",
    "    # Loop over each letter of the message.\n",
    "    for letter in message:\n",
    "        # If the letter is in the alphabet, then:\n",
    "        if letter in alphabet:\n",
    "            # 1. encode the letter\n",
    "            encoded += mapper( letter,sum( m ) )\n",
    "            # 2. advance the offset of each rotor by n=1 (modulo 26)\n",
    "            m[ 0 ] = ( m[ 0 ] + 1 ) % 26\n",
    "            for i in range( 1,len( m ) ):\n",
    "                if m[ i - 1 ] % 26 == 0:\n",
    "                    m[ i ] = ( m[ i ] + 1 ) % 26  # here as well\n",
    "\n",
    "        # Otherwise, just add the whitespace or punctuation or numeric character to the encoded string.\n",
    "        else:\n",
    "            encoded += letter\n",
    "    \n",
    "    # Finally, return the encoded message.\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example, 'HELLO' maps to 'HFNOS' if it starts with an offset of 0 on one rotor:\n",
    "#   H->H, E->F (1), L->N (2), L->O (3), O->S (4).\n",
    "text = 'HELLO'\n",
    "encode_n_rotors( text,[0,] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example, 'HELLO' maps to 'HFNOS' if it starts with an offset of [1,1] on two rotors:\n",
    "#   H->J (1+1), E->H (2+1), L->P (3+1), L->Q (4+1), O->U (5+1).\n",
    "text = 'HELLO'\n",
    "encode_n_rotors( text,[1,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brute-Force Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore several potential solutions to this problem:\n",
    "\n",
    "1.  A brute-force or exhaustive solution, which simply tries every single possible rotor configuration on an encrypted text.\n",
    "2.  A one-letter frequency attack, based on the sort of calculations you did in the lab `language`.\n",
    "3.  A three-letter frequency attack, based on the relative likelihood of a given three-letter combination in a language, like `ghi` or `nvy`.\n",
    "\n",
    "First, the brute-force solution.  In this case, we make a guess about the number of rotors employed, try every combination, and visually inspect the results for the likely decryption.\n",
    "\n",
    "For a single-rotor Enigma cipher, there is only one offset per letter, so only 26 possibilities need be tried for an exhaustive search.  For a two-rotor Enigma cipher, $26 \\times 26 = 26^2 = 676$ cases must be tested.  In general, for $n$ rotors, $26^n$ cases must be searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the function `decode_n_rotors( message,m )` which accepts an encrypted message `message` and a tuple or list of $n$ rotor offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic-caesar",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decode_n_rotors( message,m ):\n",
    "    decoded = ''\n",
    "    \n",
    "    # Convert the message to upper-case.\n",
    "    message = message.upper()\n",
    "    \n",
    "    # Reverse offsets for convenience.\n",
    "    for i in range( len( m ) ):\n",
    "        m[ i ] = -m[ i ]\n",
    "    \n",
    "    # Loop over each letter of the message.\n",
    "    for letter in message:\n",
    "        # If the letter is in the alphabet, then:\n",
    "        if letter in alphabet:\n",
    "            # 1. encode the letter\n",
    "            decoded += mapper( letter,sum( m ) )\n",
    "            # 2. decrement the offset of each rotor by n=1 (modulo 26)\n",
    "            m[ 0 ] = ( m[ 0 ] - 1 ) % 26\n",
    "            for i in range( 1,len( m ) ):\n",
    "                if m[ i - 1 ] % 26 == 0:\n",
    "                    m[ i ] = ( m[ i ] - 1 ) % 26  # here as well\n",
    "\n",
    "        # Otherwise, just add the whitespace or punctuation or numeric character to the encoded string.\n",
    "        else:\n",
    "            decoded += letter\n",
    "\n",
    "    # Finally, return the result.\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test [1,1] offset on two rotors.\n",
    "test_text = \"\"\"Mr. Fowler being a persevering man, as a good seaman should be, blockaded the house, and having met you\n",
    "succeeded by certain arguments, metallic or otherwise, in convincing you that your interests were the same as his.\"\"\"\n",
    "code_text = \"\"\"OU. JTCSMA LPUAU P FVJLYQAOGMG ODR, FY H OXYO EROBQE KAIPHA ZD, BMRGPGKMM DSQ UCJIV, SGX CWSGMG NGX DUB\n",
    "ADMNQRRTT SQ VYMPXGM ASIXRKUBB, WPFNZAYT GK IODBPVITG, LR IVVESYOVBV OFM MBVP VMTR JPWIWLACC HQES IXV KTGZ WP FHS.\"\"\"\n",
    "\n",
    "print( encode_n_rotors( test_text,[ 1,1 ] ) )\n",
    "assert encode_n_rotors( test_text,[ 1,1 ] ) == code_text\n",
    "\n",
    "print( decode_n_rotors( code_text,[ 1,1 ] ) )\n",
    "assert decode_n_rotors( code_text,[ 1,1 ] ) == test_text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test [2,2,2] offset on three rotors.\n",
    "test_text = \"\"\"Mr. Fowler being a persevering man, as a good seaman should be, blockaded the house, and having met you\n",
    "succeeded by certain arguments, metallic or otherwise, in convincing you that your interests were the same as his.\"\"\"\n",
    "code_text = \"\"\"SY. NXGWQE PTYEY T JZNPCUESKQL SHV, JC L SBCS IVSFUI OEMTLE DH, FRVKTKOQQ HWU YGNMZ, WKB GAWKQK RLB HYF\n",
    "EHQRUVVXX WU ZCQTBKQ EWMCVOYFF, ATJRDECX KO MSHFTZMXK, PW MZZIWCSZFZ SJQ QFZT ZQXV NTAMBPEGG LUIW MBZ OXKD AT JLW.\"\"\"\n",
    "\n",
    "print( encode_n_rotors( test_text,[ 2,2,2 ] ) )\n",
    "assert encode_n_rotors( test_text,[ 2,2,2 ] ) == code_text\n",
    "\n",
    "code_text = encode_n_rotors( test_text,[ 2,2,2 ] )\n",
    "print( decode_n_rotors( code_text,[ 2,2,2 ] ) )\n",
    "assert decode_n_rotors( code_text,[ 2,2,2 ] ) == test_text.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these two tools, we can encrypt any message like the Enigma would.  We can also decrypt using candidate offsets in an attempt to solve an unknown message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Consider the following message, which has been encoded by one rotor.  Write a loop which attempts all 26 possible rotor offsets and displays the result.  Use this to identify the correct offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_text = \"\"\"KGH GVJV QDCSGWW\"\"\"\n",
    "\n",
    "# Write a loop here to test all possible combinations for code_text with one rotor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Consider the following message, which has been encoded by two rotors.  Write a nested loop which attempts all $26 \\times 26 = 676$ possible rotor offsets ad displays the result.  Use this to identify the correct offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_text = \"\"\"JBTDR HQQRG NQEO JAH IE\"\"\"\n",
    "\n",
    "# Write a nested loop here to test all possible combinations for code_text with two rotors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already in trouble.  We can solve it fairly quickly for 676 possibilities, but finding the solution is becoming a problem.  As we increase the number of rotors, this is a problem for brute-force solution.\n",
    "\n",
    "One way out is to compare solutions to a dictionary of commonly used words, and flag possible matches.  Another is to analyze letter frequency in the result:  if it is close to the target language, then there may be a match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Frequency-Based Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know that we are translating an English-language message, then we know the expected relative frequency of the letters.  Based on the principles outlined in `language`, we can automatically detect likely solutions even from many candidates.\n",
    "\n",
    "Previously we used the language frequency to identify the most likely language.  For the Enigma code, we will instead use the language frequency to measure how close to English each sample is.  (Of course, it really would have been German, but we're working in English here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the ability to sort a dictionary of key-value pairs into two lists (of the keys and of the values), sorted by the values, in order to plot in order of value.  We can use this, for instance, to sort the standard English letter frequencies by order of frequency.  The blocks below carry out this sorting and plot it.  **None of these blocks requires modification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting boilerplate\n",
    "import matplotlib as mpl               # import MatPlotLib\n",
    "import matplotlib.pyplot as plt        # import PyPlot\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = 15,3  # set the aspect ratio and size of the figure\n",
    "\n",
    "# We'll use this function to plot the letters and frequencies for the next while.\n",
    "# You don't need to interpret it yet, but you can examine it as much as you like.\n",
    "def plot_freq(xs, ys, title=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    N = len(xs)\n",
    "\n",
    "    ## necessary variables\n",
    "    import numpy as np    # the Numerical Python package---you'll see this soon in lecture\n",
    "    index = np.arange(N)  # x locations for bars\n",
    "    width = 0.75          # bar width\n",
    "\n",
    "    ## the bars\n",
    "    rects1 = ax.bar(index, ys, width, color='blue')\n",
    "\n",
    "    # axes and labels\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Proportion')\n",
    "\n",
    "    ax.set_xlim(-width,len(index)+width)\n",
    "    ax.set_ylim(0,.20)\n",
    "    xTickMarks = xs\n",
    "    ax.set_xticks(index+width/2)\n",
    "    xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "    plt.setp(xtickNames, fontsize=10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a dictionary to two lists sorted by the value of the second.\n",
    "import operator\n",
    "def dict2sort(in_dict):\n",
    "    keys = sorted(in_dict, key=in_dict.get)[::-1]\n",
    "    values = []\n",
    "    for key in keys:\n",
    "        values.append(in_dict[key])\n",
    "    return keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard English frequencies, sorted by order of frequency.\n",
    "english_dict = {'A':0.0834,'B':0.0154,'C':0.0273,'D':0.0414,'E':0.126,'F':0.0203,'G':0.0192,'H':0.0611,'I':0.0671,'J':0.0023,'K':0.0087,\n",
    "                'L':0.0424,'M':0.0253,'N':0.068,'O':0.077,'P':0.0166,'Q':0.0009,'R':0.0568,'S':0.0611,'T':0.0937,'U':0.0285,'V':0.0106,\n",
    "                'W':0.0234,'X':0.002,'Y':0.0204,'Z':0.0006}\n",
    "letters, freqs = dict2sort(english_dict)\n",
    "plot_freq(letters, freqs, title='Expected Letter Frequency of English-Language Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our functions from `language` to aid in this.  Recall the function `calc_freq`, which returned a `dict` containing the relative frequency of letters in a sample of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your function here\n",
    "from string import whitespace, punctuation, digits\n",
    "from string import ascii_uppercase as alphabet\n",
    "\n",
    "def calc_freq(text):\n",
    "    # Create an empty frequency dictionary letter_freq.\n",
    "    letter_freq = {}\n",
    "    \n",
    "    # Make text upper-case.\n",
    "    text = text.upper()\n",
    "    \n",
    "    # Loop over each letter of the alphabet:\n",
    "    for letter in alphabet:\n",
    "        letter_freq[letter] = text.count(letter)\n",
    "    \n",
    "    # Make a copy of text without non-alphabet characters.\n",
    "    from string import whitespace, punctuation, digits\n",
    "    for character in whitespace+punctuation+digits:\n",
    "        text = text.replace(character, '')\n",
    "    \n",
    "    # Normalize the frequencies and put the results back into letter_freq.\n",
    "    for key in letter_freq.keys():\n",
    "        letter_freq[key] = letter_freq[key] / len(text)\n",
    "    \n",
    "    # Finally, return the dict letter_freq.\n",
    "    return letter_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"'LAY “XKJNTTBDOI” SATJNBD YON RV VXMXNFZDD CTLIKRF IB DSQ ETQC FNGWAOQ VHPUH ICVYMBCTAAG QJ S WYXEJYK ASG FEQIBTJLWQ OM\n",
    "UZFBNZ IBYMS. BNWLTANP CRP EHPYUUM IA PEGR PBRHV NY VACOYEVPAO KAY XKJNTTBDOI SATJNBD, UG WH QCEINP BOTAMNB IFYF BX NPRVBT QEV\n",
    "BIRBQSIHCWI HUTXDDLNYS UKEUMCKKQ NF BP LRYKNZJV GMEWPRCW HL V OCZL PT FSRVBBJLWQ IOGYRTEY, XKKOUUCEPJ VYMMSNMGSH, QEV LI AKOSH.\n",
    "UJH JZTKIVOYFNZ EHFTEYHO FLVPNYII GYM, QYHQISG, JYW LUHA FL DBEK GFYL, IWN T TNJT SYGLYI PEC BOOSYYGITN XFYOSGI WGK YSLIGBIU\n",
    "WVJGAUNXE MF WCLFDOCIC QFD LFCWY IBUKBZGF HTSYFBKPA. F FNPF UKTXATH DZ SVJT QE SVWJQKR NF UJH VKSICSZZF CU JYW VIHLRRZBMG QYRIMAC,\n",
    "QGAQIYFFL, UIZ PM EOSVK XT UVN KYAGVTH. KZBM REIJ HNDNXHJ G KNFPXBDBUEL HZ ODB RGEPTB SK LBVMEUBBH EW S KYVH SYQIBDOI JDWZNDERR XD\n",
    "KWKGN KC ANMQWWEGRL VDWNRFH. QTUHLYEKE SO NA GIKOUQCSZA, O CKDTXL DO ZMLPVVDFQK PN RDD PSRYDSE WVJ YC VRJVWIS JVEW LJ M ZPSYAGY.\n",
    "(VHXL SUSKQK, 1937)\\n'\"\"\"\n",
    "\n",
    "code_dict = calc_freq(code)\n",
    "code_letters, code_freqs = dict2sort(code_dict)\n",
    "plot_freq(letters, freqs, title='Expected Letter Frequency of English-Language Text')\n",
    "plot_freq(code_letters, code_freqs, title='Letter Frequency in Code Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Caesar cipher is particularly weak, and only worked in an ancient world with low literacy and no prior cryptographic experience.  If you analyze the frequency of the letters, for instance, and guess that the most frequent letter in a long encoded text corresponds to E, the second most frequent to A, etc., then you can soon break Caesar ciphers even if you do not know the offset ahead of time.\n",
    "\n",
    "However, the Enigma cipher is much more clever.  The occurrence of each letter is nearly uniform, leaving us no direct way to attempt to break this code by a frequency analysis!  Higher-order patterns must be identified and analyzed, which is precisely what the British Ultra project did before and during World War II.\n",
    "\n",
    "Instead, we will use brute-force to solve the encodings, then use frequency analysis to recommend likely solutions to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following encoded communiqué intercepted from a submarine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boss_encoded = \"\"\"RBFRUU LH MPXJCRHG GYWOUO JDEMPY. SUGLA WCWOEDT.\n",
    "NDWY KUMVI AAFWIYFF 0830A UE 9863, YLSQSG WAT\n",
    "NBVMBPP GKTDKQ WYBNBCR, SQHII KPOQD VZBHH. Y RE\n",
    "YIGHLUHNH VLJ KUMVI. MMECBUKWK ZVHIQ EOVTWJKU UK,\n",
    "GTZQ BDHKZ-GIMPE-CZSU, HRVIL NXEC, HVGXRZDBNT PBL\n",
    "MAVVLGFS URVPE\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your challenge is to solve this.  All you know is that it was encoded with a four-rotor Enigma device.\n",
    "\n",
    "-   Compose a series of loops to solve the encoded message using three rotors.  Store the decrypted text in a dictionary `messages`.  The key should be the rotor setting (as a tuple) and the value should be the decrypted message.  This dictionary should have $26^3 = 17,576$ entries after you are done.  _This may take several minutes to run._  The `print` statement lets you monitor the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3c981607896c8407",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "messages = {}\n",
    "for i in range( 26 ):\n",
    "    for j in range( 26 ):\n",
    "        print( i,j,end='\\t' )\n",
    "        for k in range( 26 ):\n",
    "            text = ???\n",
    "            messages[ ( i,j,k ) ] = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e30ef48e05dbe752",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a testing cell; don't change it\n",
    "assert len( messages ) == 17576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have from `language` some tools which let you compare the similarity of letter frequency, such as `calc_match` and the reference letter frequency for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_match( L_text,L_ref ):\n",
    "    '''\n",
    "    Compute the difference of two dictionaries with the same keys.\n",
    "    Args:\n",
    "        L_text: The distribution of letter frequency of the analyzed text\n",
    "        L_ref: The distribution of letter frequency of one language\n",
    "    Returns:\n",
    "        f: float, a caculated metric showing the difference between two dicts\n",
    "    '''\n",
    "\n",
    "    # Create an empty dictionary `L_diff`.\n",
    "    L_diff = { }\n",
    "    \n",
    "    # Loop through the keys of the dictionaries (either by loading `alphabet` as above or by using `L_ref.keys()`).\n",
    "    for letter in L_ref:\n",
    "        # Calculate the absolute value of the difference between each dictionary value for each letter\n",
    "        L_diff[ letter ] = abs( L_text[ letter ] - L_ref[ letter ] )\n",
    "    \n",
    "    # Next, loop through `L_diff` and sum all of the differences into the variable `f`.\n",
    "    f = 0.0\n",
    "    for letter in L_diff:\n",
    "        f += L_diff[letter]\n",
    "    \n",
    "    # Finally, return the metric `f`.\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "example_data = requests.get( 'https://raw.githubusercontent.com/UI-CS101/cs101-wiki/master/lab07/english' ).text\n",
    "L_eng = { }\n",
    "for line in example_data.split( '\\n' ):\n",
    "    try:\n",
    "        letter,freq = line.split( ',' )\n",
    "        L_eng[ letter ] = float( freq[ :-2 ] ) / 100\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this on the first decryption attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_attempt = messages[ ( 0,0,0 ) ]\n",
    "print( first_attempt )\n",
    "print( calc_match( calc_freq( first_attempt ),L_eng ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual frequency value by itself doesn't tell us much.  We just want to filter for the _best_ fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a loop or series of loops to calculate the similarity $f$ using `calc_match` for every decryption attempt.  Store this result in a dictionary `fs`.  The key should be the rotor setting (as a tuple) and the value should be the fit $f$.  This dictionary should have $26^3 = 17,576$ entries after you are done.  _This may take several minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = { }\n",
    "for key in messages:\n",
    "    fs[ key ] = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Filter for the ten most likely keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to change this, it works already\n",
    "dict2sort( fs )[ 0 ][ -10: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Output these candidate messages.  (There may be more than one good match due to the probabilistic approach we are taking.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to change this, it works already\n",
    "for key in dict2sort( fs )[ 0 ][ -10: ]:\n",
    "    print( messages[ key ] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
