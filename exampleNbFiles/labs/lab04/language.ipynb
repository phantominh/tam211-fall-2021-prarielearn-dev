{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `lab04`—Probabilistic Language Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/lab05-header-bkgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❖ Objectives\n",
    "\n",
    "-   Work with online data sources (`requests`).\n",
    "-   Learn the standard pipeline of data analysis:  data cleaning and preparation, data processing, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Letter Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random sampling of English text produces approximately the following letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-eng.png\" width=\"80%;\"/>\n",
    "\n",
    "whereas Latin has the letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-lat.png\" width=\"80%;\"/>\n",
    "\n",
    "and Welsh has the letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-cym.png\" width=\"80%;\"/>\n",
    "\n",
    "Each language tends to have a unique \"fingerprint\" because of the relative frequency of letters and sounds.  Such letter frequency information could be used, for instance, to determine how much type should be ordered for a letterpress, or how many tiles should be included in a country-specific version of Scrabble.\n",
    "\n",
    "Today you will use this fingerprint to assign rough probabilities to the likely language of a given text sample in an unknown language.  (This is similar to what [Google Translate](https://translate.google.com/) does when it auto-detects the language of a text sample, except that it uses whole words instead of letter frequencies to make its guess.)\n",
    "\n",
    "There are three steps in the data processing pipeline for you to complete today:\n",
    "\n",
    "1.  Count the frequency of each letter in the text sample.  Then divide the resulting list of frequencies by the total number of letters.  (That is, *normalize* the frequencies.)\n",
    "1.  Load the reference language frequencies.\n",
    "1.  Predict the most likely language based on comparing the text letter frequency with each of the reference frequencies.\n",
    "\n",
    "Our intent is to reproduce this toolset:\n",
    "\n",
    "![](./img/flowchart.png)\n",
    "\n",
    "You will use and/or compose these several functions in order to extract information from the data sources (here listed as \"language files\" and use it to study text samples.\n",
    "\n",
    "<br/>\n",
    "<div class=\"alert alert-info\">\n",
    "We will restrict ourselves to the 26 letters of the basic Latin alphabet, disallowing diacritics ('naïve'→'naive'), accents ('recherché'→'recherche'), and nonbasic letters ('Skjærvø'→'Skjarvo').  (If you speak another language in which this matters, we sincerely apologize for this rank philistinism.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Calculate the normalized letter frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate letter frequencies, you need a list of letters and the string in all upper-case letters.  To avoid confusion, we will rename this built-in string `ascii_uppercase` as `alphabet` when we `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_uppercase as alphabet\n",
    "# use `alphabet` as ascii_uppercase from now on\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our example text.\n",
    "text = 'Jackdaws love my big Sphinx of Quartz.'\n",
    "text = text.upper()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an empty frequency dictionary `letter_freq`.  Loop over each letter of the `alphabet` and `count` the number of times each letter occurs in `text`.  Add this count to `letter_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_freq = {}  # a blank dictionary\n",
    "\n",
    "# Loop over the alphabet.\n",
    "for letter in alphabet:\n",
    "    # For each letter, get the number of times it occurs in the string `text`.\n",
    "    letter_count = text.count(letter)\n",
    "    letter_freq[letter] = letter_count\n",
    "\n",
    "letter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to normalize the values.  To do this, we need to calculate the total number of letters in `text` (letters, NOT whitespace or punctuation).  Since this is a bit involved, the following lines of code will give us a copy of `text` without whitespace or punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are built-in collections of characters, useful for just this sort of filtering.\n",
    "from string import whitespace, punctuation, digits\n",
    "print(whitespace, punctuation, digits)\n",
    "for character in whitespace+punctuation+digits:\n",
    "    text = text.replace(character, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set each frequency value in the dictionary to its normalized value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in letter_freq.keys():\n",
    "    letter_freq[key] = letter_freq[key] / len(text)\n",
    "letter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will turn the above process into a general function to process a string into its letter frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `calc_freq` which accepts a string `text`.  `calc_freq` should `return` a dictionary containing the normalized frequency by letter.\n",
    "    \n",
    "    You should use the above process just outlined to write this function.\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "When diagnosing the behavior of your code, we encourage you to use `print` statements freely.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "calc_freq",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "from string import whitespace, punctuation, digits\n",
    "from string import ascii_uppercase as alphabet\n",
    "\n",
    "def calc_freq(text):\n",
    "    '''\n",
    "    Calculate the frequency in the text of each letter\n",
    "    Args:\n",
    "        string: a piece of text \n",
    "    Returns:\n",
    "        dict: the frequency of each letter in a dictionary (e.g. letter_freq['A'] gives 0.06)\n",
    "    '''\n",
    "    # Create an empty frequency dictionary letter_freq.\n",
    "    letter_freq = {}\n",
    "    \n",
    "    # Make text upper-case.\n",
    "    ## YOU WRITE THIS LINE\n",
    "    \n",
    "    # Loop over each letter of the alphabet:\n",
    "    for letter in alphabet:\n",
    "        # Count the number of times each letter occurs in text.\n",
    "        ## YOU WRITE THIS LINE\n",
    "        # Add this count to letter_freq.\n",
    "        ## YOU WRITE THIS LINE\n",
    "    \n",
    "    # Make a copy of text without non-alphabet characters.\n",
    "    from string import whitespace, punctuation, digits\n",
    "    for character in whitespace+punctuation+digits:\n",
    "        text = text.replace(character, '')\n",
    "    \n",
    "    # Normalize the frequencies and put the results back into letter_freq.\n",
    "    for key in letter_freq.keys():\n",
    "        letter_freq[key] = letter_freq[key] / len(text)\n",
    "    \n",
    "    # Finally, return the dict letter_freq.\n",
    "    return letter_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any sample text, but the following is provided for convenience.\n",
    "text = \"\"\"Neither the naked hand nor the understanding left to itself can effect much. It is by instruments and helps that the work is done,\n",
    "which are as much wanted for the understanding as for the hand. And as the instruments of the hand either give motion or guide it, so the\n",
    "instruments of the mind supply either suggestions for the understanding or cautions.  (Francis Bacon, Novum Organon, Aphorism II)\"\"\"\n",
    "calc_freq(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_freq-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_text1 = \"\"\"The study of nature with a view to works is engaged in by the mechanic, the mathematician, the physician, the alchemist, and\n",
    "the magician; but by all (as things now are) with slight endeavor and scanty success.  (Francis Bacon, Novum Organon, Aphorism V)\"\"\"\n",
    "result_text1 = calc_freq(test_text1)\n",
    "assert isclose(result_text1['T'], 0.09045226130653267) and \\\n",
    "       isclose(result_text1['Q'], 0.0) and \\\n",
    "       isclose(result_text1['Y'], 0.0251256281407035)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_freq-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "test_text2 = \"\"\"In order to penetrate into the inner and further recesses of nature, it is necessary that both notions and axioms be derived\n",
    "from things by a more sure and guarded way, and that a method of intellectual operation be introduced altogether better and more certain.\n",
    "(Francis Bacon, Novum Organon, Aphorism XVIII)\"\"\"\n",
    "result_text2 = calc_freq(test_text2)\n",
    "assert isclose(result_text2['K'], 0.0) and \\\n",
    "       isclose(result_text2['N'], 0.09523809523809523) and \\\n",
    "       isclose(result_text2['L'], 0.015873015873015872)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Load the reference language frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each language has a characteristic pattern of letter frequencies.  In previous labs, we stored data like these on the disk as files.  This time, we will use the `requests` library to acquire data available on the Web.  Reference frequencies for the following languages are available.  (These frequencies are derived from the work of Stefan Trost<sup>[[Trost2015](http://www.sttmedia.com/characterfrequencies)]</sup> and used with his permission.)\n",
    "\n",
    "- [Afrikaans](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/afrikaans)\n",
    "- [Catalan](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/catalan)\n",
    "- [Danish](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/danish)\n",
    "- [English](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/english)\n",
    "- [Finnish](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/finnish)\n",
    "- [French](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/french)\n",
    "- [German](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/german)\n",
    "- [Latin](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/latin)\n",
    "- [Polish](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/polish)\n",
    "- [Portuguese](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/portuguese)\n",
    "- [Spanish](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/spanish)\n",
    "- [Welsh](https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/welsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "example_data = requests.get( 'https://raw.githubusercontent.com/UI-CS101/cs101-wiki/master/lab07/danish' )\n",
    "print( example_data.text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the reference language frequencies, you will first write a function `load_ref` to load a given language reference URL.  You will write a function `load_languages` which uses `load_ref` with a list of available languages to create a `dict` of all of the language frequencies available.\n",
    "\n",
    "Take a look at the format of `example_data` (Danish):\n",
    "    \n",
    "    A,8.27%\n",
    "    B,1.42%\n",
    "    C,0.45%\n",
    "    ...\n",
    "\n",
    "If you wanted to read this into a dictionary, you could take each line and split it by the comma.\n",
    "\n",
    "Since you want to include the second part as a `float`, you need to convert it.  Try this out directly (but it will fail):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict = {}\n",
    "testDict['A'] = float('8.27%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "The problem is that Python doesn't know if the percent sign in the string is supposed to be a string format marker or actually a percent sign, so it doesn't correctly parse this string into a `float`.\n",
    "</div>\n",
    "\n",
    "-  In order to convert a string of a percent value into a float, compose a function `p2f` (short for `percentToFloat`) which accepts a string `value`.  `p2f` `strip`s the percent sign off of the string `value`, converts this to a `float`, and then divides by `100` and `return`s the result.  (Python provides a function `round` which you may elect to use here to simplify the result, but this is not required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def p2f(value):\n",
    "    '''\n",
    "    Take a string in the format of '8.27%', \n",
    "    and convert it to a number (0.0827 in this case).\n",
    "    Args:\n",
    "        string: n%\n",
    "    Returns:\n",
    "        float: a number between 0 and 1\n",
    "    '''\n",
    "    # Strip any whitespace and then strip the percent sign off of value.\n",
    "    ## YOU WRITE THIS\n",
    "    \n",
    "    # Convert the result to a float and divide by 100.\n",
    "    result = ## YOU WRITE THIS\n",
    "    \n",
    "    # Finally, return the result.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any sample value, but the following is provided for convenience.\n",
    "value = \"5.6%\"\n",
    "p2f(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2f-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "assert isclose(p2f('1.79%'), 0.0179)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to add to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict = {}\n",
    "testDict['A'] = p2f('8.27%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `open_url` which accepts a string `language`.  `open_url` should `return` a `str` containing the reference language letter frequencies stored at the URL of the form given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "open_url",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def open_url( language ):\n",
    "    '''\n",
    "    Open the language URL using `requests` and read the data out via the text attribute.\n",
    "    The URL you need is of the form\n",
    "       https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/language\n",
    "    where you'll replace language with the string passed in (think of string format operators).\n",
    "    For instance, if language == 'english', then the URL should be\n",
    "       https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/english\n",
    "    Args:\n",
    "        string: language name\n",
    "    Returns:\n",
    "        The predicted distribution of each character in the given language\n",
    "    '''\n",
    "    \n",
    "    url_prefix = 'https://raw.githubusercontent.com/UI-CS101/cs101-fa16/master/lab07/'\n",
    "    url_suffix = '' # Construct url here from `url_prefix` and `language`\n",
    "    url = url_prefix + url_suffix\n",
    "    language_data = requests.get( url ).text\n",
    "    \n",
    "    # Finally, return the string `language_data`.\n",
    "    return language_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any language listed above, but the following is provided for convenience.\n",
    "language = 'polish'\n",
    "open_url(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "open_url-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_ref = open_url('english')\n",
    "assert test_ref.split('\\n')[0] == 'A,8.34%'\n",
    "assert len(test_ref) == 209\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `load_ref` which accepts a string `language`.  `load_ref` should `return` a `dict` containing the reference language letter frequencies stored at the correct URL (using `open_url`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load_ref",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_ref( language ):\n",
    "    '''\n",
    "    Open the language URL using `open_url` and read the data out via the text attribute.\n",
    "    Then, parse the text line by line, and store the values in a dictionary.\n",
    "    Args:\n",
    "        string: language name\n",
    "    Returns:\n",
    "        dict: The predicted distribution of each character in the given language\n",
    "              in the format of {letter: percentage} ('A': 0.08, 'B\": 0.065 ...)\n",
    "    '''\n",
    "\n",
    "    # Create an empty dictionary called `languages`.\n",
    "    languages = {}\n",
    "    \n",
    "    # Open the language URL.\n",
    "    data = open_url( language ) # data is a string\n",
    "    data = data.strip().split( \"\\n\" ) #convert it from a string to a list\n",
    "    \n",
    "    for line in data: #data should be a list not a string\n",
    "    # Loop over each line in the data.\n",
    "        # Split each line at the comma.\n",
    "        # The first part should be assigned to a variable `letter`, the second part to a variable `frequency`.\n",
    "        \n",
    "        \n",
    "        # Add the second part (the frequency) to the dictionary as the value (converted to a float)\n",
    "        # with the first part (the letter) as the key.  MAKE SURE THE KEY IS UPPER-CASE!\n",
    "        languages[ letter ] = p2f( frequency )\n",
    "    \n",
    "    # Finally, return the dict `languages`.\n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any language listed above, but the following is provided for convenience.\n",
    "language = 'polish'\n",
    "load_ref(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_ref-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "language = 'english'\n",
    "test_ref = load_ref(language)\n",
    "assert isclose(test_ref['A'], 0.0834)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to write a function `load_languages` which accepts a list of languages and creates a dictionary for each using `load_ref`.  Then all of these dictionaries will be added to an overall dictionary, by language.  That is, `master` will look something like this:\n",
    "\n",
    "        `master` is a dictionary with keys:\n",
    "            'afrikaans' -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "            'catalan'   -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "            'danish'    -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "\n",
    "Specifically,\n",
    "    \n",
    "    master['afrikaans']  # returns a dict containing the reference language frequencies for Afrikaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a list of available languages.  You can then open each of them, reading them into a dictionary using `load_ref`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languageNames = [ 'afrikaans','catalan','danish','english','finnish','french',\n",
    "                  'german','latin','polish','portuguese','spanish','welsh' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop over the list `languageNames`, and for each language we can 1) create a dictionary using `load_ref` and 2) add this dictionary to the master dictionary `master` with the language as the key.  Do this in the function `loadLanguages` (which need have no parameters) and `return` `master`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "load_languages",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_languages():\n",
    "    '''\n",
    "    For each language, construct a dictionary and store the dictionary as the value\n",
    "    of the master dictionary.\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        dict: The predicted distribution of each language \n",
    "              in the format of {language: distribution} \n",
    "              ('English': {'A': 0.08, 'B\": 0.065 ...}, 'Welsh\": ...)\n",
    "    '''\n",
    "\n",
    "    # Create an empty dictionary `master`.\n",
    "    master = {}\n",
    "    # master: language(str) -> dict\n",
    "    # dict: character(str) -> frequency(float)\n",
    "    # Get a list of languages available.\n",
    "    ## YOU WRITE THIS LINE (you can copy the code block above as a starting point but it needs to be in-scope)\n",
    "    \n",
    "    # Call `load_ref` on each of these and add the resulting dictionary as a value to `master` with key `language`.\n",
    "    ## YOU WRITE THIS LOOP\n",
    "    \n",
    "    # Finally, return the dict `master`.\n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell.\n",
    "master = load_languages()\n",
    "print(master.keys())\n",
    "print(master['welsh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_languages-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_master = load_languages()\n",
    "assert isclose(test_master['english']['A'], 0.0834)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_languages-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_master = load_languages()\n",
    "assert isclose(test_master['catalan']['Z'], 0.001),'Check the URL.  You may be writing the open_url() function with the language given in the test case, not the one given in the function parameters.'\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Predict the most likely language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `load_languages` and `calc_freq`, you are now prepared to assess the similarity of a text to a reference language.  This last step is the most mathematically involved.\n",
    "\n",
    "We will define a frequency metric $f$ to assess the closeness of the match between two sets of frequencies.  In human language, you will calculate the difference between the two lists $L_{\\text{unknown}}$ and $L_{\\text{ref}}$, which yields a third list of the differences.  To make this list positive, take its absolute value.  (This keeps equal but opposite errors from canceling each other out.)  To provide a single value to compare, let $f$ be equal to the sum of these absolute values.  Thus a low value of $f$ means a low difference and a better fit between two frequency distributions than a high value of $f$.  As an equation,\n",
    "\n",
    "$$\n",
    "f \\left( L_{\\text{text}}, L_{\\text{ref}} \\right) =\n",
    "\\sum_{\\text{letters}} \\left| L_{\\text{text}} - L_{\\text{ref}}\\right| \\text{.}\n",
    "$$\n",
    "\n",
    "To be clear, the metric we are calculating, $f$, is a metric for how *different* two letter frequency distributions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `calc_match` which accepts two dictionaries `L_text` and `L_ref`.  `calc_match` should return the calculated metric `f` according to the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "calc_match",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_match(L_text, L_ref):\n",
    "    '''\n",
    "    Compute the difference of two dictionaries.\n",
    "    Args:\n",
    "        L_text: The distribution of letter frequency of the analyzed text\n",
    "        L_ref: The distribution of letter frequency of one language\n",
    "    Returns:\n",
    "        f: float, a caculated metric showing the difference between two dicts\n",
    "    '''\n",
    "\n",
    "    # Create an empty dictionary `L_diff`.\n",
    "    L_diff = {}\n",
    "    \n",
    "    # Loop through the keys of the dictionaries (either by loading `alphabet` as above or by using `L_ref.keys()`).\n",
    "    # Calculate the absolute value of the difference between each dictionary value for each letter\n",
    "    #     L_diff['A'] = abs(L_text['A'] - L_ref['A'])  # for each letter (or key in L_ref)\n",
    "    ## YOU WRITE THIS LOOP\n",
    "    \n",
    "    # Next, loop through `L_diff` and sum all of the differences into the variable `f`.\n",
    "    f = 0.0\n",
    "    for letter in L_diff:\n",
    "        f += L_diff[letter]\n",
    "    \n",
    "    # Finally, return the metric `f`.\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your code here.  You may edit this cell.\n",
    "text   = '''The conclusions of human reason as ordinarily applied in matters of nature, I call for the sake of distinction Anticipations of\n",
    "Nature (as a thing rash or premature). That reason which is elicited from facts by a just and methodical process, I call Interpretation of\n",
    "Nature.  (Francis Bacon, Novum Organon, Aphorism XXVI)'''\n",
    "L_text = calc_freq(text)\n",
    "master = load_languages()\n",
    "L_ref  = master['english']\n",
    "f = calc_match(L_text, L_ref)\n",
    "print('welsh, %f'%f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "surname_list-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test self-similarity and similarity across languages\n",
    "from numpy import isclose\n",
    "master = load_languages()\n",
    "assert isclose(calc_match(master['danish'], master['danish']), 0.0)\n",
    "assert isclose(calc_match(master['english'], master['finnish']), 0.5338)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "count_names-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "from numpy import isclose\n",
    "text   = '''The conclusions of human reason as ordinarily applied in matters of nature, I call for the sake of distinction Anticipations of\n",
    "Nature (as a thing rash or premature). That reason which is elicited from facts by a just and methodical process, I call Interpretation of\n",
    "Nature.  (Francis Bacon, Novum Organon, Aphorism XXVI)'''\n",
    "L_text = calc_freq(text)\n",
    "master = load_languages()\n",
    "L_ref  = master['english']\n",
    "f = calc_match(L_text, L_ref)\n",
    "print('welsh, %f'%f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will capture the above logic in a function `find_best_fit` which will accept a string `text` and a dictionary of reference language dictionaries `master`.  `find_best_fit` compares `text` against all languages in `master`.  `find_best_fit` will return the language corresponding to the lowest value of `f` across the different available reference languages.\n",
    "\n",
    "This is a freebie, so you can see the fruits of your labor in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code already works---you don't need to write anything here.\n",
    "def find_best_fit(text, master):\n",
    "    # Create an empty dictionary `fs`.\n",
    "    fs = {}\n",
    "    \n",
    "    L_text = calc_freq(text)\n",
    "    \n",
    "    # Loop through the keys of `master` (by using `master.keys()`).\n",
    "    for language in master.keys():\n",
    "        # Calculate `f` for each using `calc_match` and store the result in `fs` with the key of the language.\n",
    "        L_ref = master[language]\n",
    "        fs[language] = calc_match(L_text, L_ref)\n",
    "    \n",
    "    # Finally, return the language corresponding to the minimum `f` in `fs` and the value of `f` in a tuple.\n",
    "    best_language = min(fs, key=fs.get)  # calculate the minimum value of any key in `fs`\n",
    "    best_f = fs[best_language]\n",
    "    return (best_language, best_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "text = '''\n",
    "    Soren Kierkegaard (\"Frygt og baven:  Dialektisk lyrik\", 1843)\n",
    "    Er det virkelig saa, er al den Spidsborgerlighed, jeg seer i Livet, som jeg ikke lader mit Ord men min Gjerning domme, er den virkelig\n",
    "    ikke hvad den synes, er den Vidunderet? Det lod sig jo tanke; thi hiin Troens Helt havde jo en paafaldende Lighed dermed; thi hiin Troens\n",
    "    Helt var end ikke Ironiker og Humorist, men noget endnu Hoiere. Der tales i vor Tid meget om Ironi og Humor, Lsær af Folk, som aldrig have\n",
    "    formaaet at praktisere deri, men som desuagtet vide at forklare Alt. Jeg er ikke ganske ubekjendt med disse tvende Lidenskaber, jeg veed\n",
    "    lidt mere om dem end hvad der staaer i tydske og tydsk-danske Compendier. Jeg veed derfor, at disse tvende Lidenskaber ere vasentlig\n",
    "    forskjellige fra Troens Lidenskab. Ironi og Humor reflektere ogsaa paa sig selv og hore derfor hjemme i den uendelige Resignations\n",
    "    Sphare, de have deres Elasticitet i, at Individet er incommensurabelt for Virkeligheden.\n",
    "    '''\n",
    "master = load_languages()\n",
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "from numpy import isclose\n",
    "text = '''\n",
    "    Below the thunders of the upper deep;\n",
    "    Far, far beneath in the abysmal sea, \n",
    "    His ancient, dreamless, uninvaded sleep\n",
    "    The Kraken sleepeth: faintest sunlights flee\n",
    "    About his shadowy sides: above him swell\n",
    "    Huge sponges of millennial growth and height; \n",
    "    And far away into the sickly light, \n",
    "    From many a wondrous grot and secret cell\n",
    "    Unnumbered and enormous polypi\n",
    "    Winnow with giant arms the slumbering green.\n",
    "    There hath he lain for ages and will lie\n",
    "    Battening upon huge sea-worms in his sleep,\n",
    "    Until the latter fire shall heat the deep;\n",
    "    Then once by man and angels to be seen,\n",
    "    In roaring he shall rise and on the surface die.\n",
    "    (Alfred Lord Tennyson)\n",
    "    '''\n",
    "master = load_languages()\n",
    "language, f = find_best_fit(text, master)\n",
    "assert isclose(f, 0.198151072125)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most complex program you've yet written.  Let's review its overall logic:\n",
    "\n",
    "![](./img/flowchart.png)\n",
    "\n",
    "It's easy to get lost, but charting out your program's logic can help you navigate and think about coding challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The lab is now complete, but you may find it interesting to use this function to predict the language of the following text samples, or find your own online and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = load_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Onder hierdie hoof wil ek u kortliks op grondige teëstelling wys en ook op verbinding. Die satiere, immers, is algemeen opgevat as\n",
    "spottende uiting van tenminste ontevredenheid of misnoeë ten opsigte van slegtheid en dwaasheid, bestaande wantoestande in die werklikheid,\n",
    "met die doel om daarteen gedagte, wil en gevoel op te wek. Hierby wil ek vooropstel die verskillende grade ven gevoel in satieriese spot,\n",
    "variërende tussen die uiterstes van hoon en sarkasme aan die een kant en gemoedelikheid van komiek en mildheid van humor aan die ander. 'n\n",
    "Definiesie van satiere wat enkel op hoon en bitterheid wys, skyn my egter nie ruim genoeg vir hierdie begrip nie. Hierteen kan miskien\n",
    "ingebring word dat ons dan die satiere nie langer in sy essensieelste vorm kry nie.  (F.E.J. Malherbe, Humor in die algemeen en sy uiting in\n",
    "die Afrikaanse letterkunde)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Tots els essers humans neixen lliures i iguals en dignitat i en drets. Son dotats de rao i de consciencia, i han de comportar-se\n",
    "    fraternalment els uns amb els altres.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You will note that, unsurprisingly, short text samples are harder to statistically analyze in this manner.  The foregoing sample is written in Catalan, but this method detects a slightly different language.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Quoi que puisse dire Aristote, et toute la philosophie, il n'est rien d'egal\n",
    "au tabac ; c'est la passion des honnetes gens ; et qui vit sans tabac n'est pas digne\n",
    "de vivre. Non seulement il rejouit et purge les cerveaux humains, mais encore il\n",
    "instruit les ames a la vertu, et l'on apprend avec lui a devenir honnete homme. Ne\n",
    "voyez-vous pas bien, des qu'on en prend, de quelle maniere obligeante on en use avec\n",
    "tout le monde, et comme on est ravi d'en donner a droite et a gauche, partout ou l'on\n",
    "se trouve ? On n'attend pas meme qu'on en demande, et l'on court au-devant du souhait\n",
    "des gens ; tant il est vrai que le tabac inspire des sentiments d'honneur et de vertu\n",
    "a tous ceux qui en prennent. Mais c'est assez de cette matiere, reprenons un peu notre\n",
    "discours. Si bien donc, cher Gusman, que done Elvire, ta maitresse, surprise de notre\n",
    "depart, s'est mise en campagne apres nous ; et son coeur, que mon Maitre a su toucher\n",
    "trop fortement, n'a pu vivre, dis-tu, sans le venir chercher ici. Veux-tu qu'entre-nous\n",
    "je te dise ma pensee ? J'ai peur qu'elle ne soit mal payee de son amour, que son voyage\n",
    "en cette ville produise peu de fruit, et que vous eussiez autant gagne a ne bouger de la.\n",
    "\n",
    "(Moliere, Don Juan ou le Festin de pierre)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
    "tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua,\n",
    "rocin flaco y galgo corredor. Una olla de algo mas vaca que carnero,\n",
    "salpicon las mas noches, duelos y quebrantos los sabados, lantejas los\n",
    "viernes, algun palomino de anadidura los domingos, consumían las tres\n",
    "partes de su hacienda. El resto della concluian sayo de velarte, calzas de\n",
    "velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias de\n",
    "entresemana se honraba con su vellori de lo mas fino. Tenia en su casa una\n",
    "ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte,\n",
    "y un mozo de campo y plaza, que asi ensillaba el rocin como tomaba la\n",
    "podadera. Frisaba la edad de nuestro hidalgo con los cincuenta anos; era de\n",
    "complexion recia, seco de carnes, enjuto de rostro, gran madrugador y amigo\n",
    "de la caza. Quieren decir que tenia el sobrenombre de Quijada, o Quesada,\n",
    "que en esto hay alguna diferencia en los autores que deste caso escriben;\n",
    "aunque, por conjeturas verosimiles, se deja entender que se llamaba\n",
    "Quejana. Pero esto importa poco a nuestro cuento; basta que en la narracion\n",
    "del no se salga un punto de la verdad.\n",
    "(Miguel de Saavedra Cervantes, Don Quixote)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is %s with a metric of %f.'%(language,f))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
